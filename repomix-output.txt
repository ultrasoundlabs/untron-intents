This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
blockchain/
  ethereum.py
  tron.py
database/
  __init__.py
  models.py
polling/
  order_listener.py
  receiver_listener.py
config.py
endpoints.py
main.py
utils.py

================================================================
Files
================================================================

================
File: blockchain/ethereum.py
================
import json
import logging
from typing import Optional, Dict, Any, Tuple
from web3 import Web3
from web3.contract import Contract, AsyncContract
from eth_account.account import Account
from web3.middleware import AsyncWeb3
from web3.providers import AsyncHTTPProvider

from ..config import CONFIG, GAS_PRICE_MULTIPLIER, MAX_GAS_PRICE, ABIS

logger = logging.getLogger(__name__)

class EthereumClient:
    def __init__(self):
        """Initialize Ethereum client and load contracts."""
        # Initialize web3 instances and contracts for each chain
        self.web3_by_chain = {}
        self.contracts_by_chain = {}
        self.factory_by_chain = {}
        self.account = Account.from_key(CONFIG["ethereum_private_key"])
        
        for chain in CONFIG["chains"]:
            web3 = AsyncWeb3(AsyncHTTPProvider(chain["rpc"]))
            
            # Initialize UntronTransfers contract
            contract = web3.eth.contract(
                address=chain["contract_address"],
                abi=ABIS["untron"]
            )
            
            # Initialize factory contract for this chain
            factory = web3.eth.contract(
                address=CONFIG["receiver_factory_address"],
                abi=ABIS["factory"]
            )
            
            self.web3_by_chain[chain["name"]] = web3
            self.contracts_by_chain[chain["name"]] = contract
            self.factory_by_chain[chain["name"]] = factory
            
            logger.info(
                f"Initialized Ethereum client for chain {chain['name']} "
                f"at {chain['contract_address']}, "
                f"factory at {CONFIG['receiver_factory_address']}"
            )

    def get_web3(self, chain_name: str) -> Web3:
        """Get Web3 instance for a specific chain."""
        if chain_name not in self.web3_by_chain:
            raise ValueError(f"Unknown chain: {chain_name}")
        return self.web3_by_chain[chain_name]

    def get_contract(self, chain_name: str) -> Contract:
        """Get UntronTransfers contract for a specific chain."""
        if chain_name not in self.contracts_by_chain:
            raise ValueError(f"Unknown chain: {chain_name}")
        return self.contracts_by_chain[chain_name]

    def get_factory(self, chain_name: str) -> Contract:
        """Get ReceiverFactory contract for a specific chain."""
        if chain_name not in self.factory_by_chain:
            raise ValueError(f"Unknown chain: {chain_name}")
        return self.factory_by_chain[chain_name]

    async def generate_receiver_address(self, chain_name: str, tron_bytes: bytes) -> str:
        """
        Generate receiver address from Tron address bytes using the factory's
        deterministic address generation (CREATE2).
        """
        factory = self.get_factory(chain_name)
        logger.info(f"Generating receiver address for Tron bytes: {tron_bytes.hex()}")
        address = await factory.functions.generateReceiverAddress(tron_bytes).call()
        logger.info(f"Generated receiver address: {address}")
        return address

    async def call_intron(self, chain_name: str, tron_bytes: bytes) -> Dict[str, Any]:
        """
        Call intron() through the factory contract, which handles receiver deployment
        and proper parameter passing.
        """
        factory = self.get_factory(chain_name)
        logger.info(f"Calling intron via factory for Tron bytes: {tron_bytes.hex()}")
        
        try:
            nonce = await self.web3_by_chain[chain_name].eth.get_transaction_count(self.account.address)
            gas_price = await self.web3_by_chain[chain_name].eth.gas_price
            chain_id = await self.web3_by_chain[chain_name].eth.chain_id
            
            # Build intron transaction through factory
            tx = await factory.functions.intron(tron_bytes).build_transaction({
                "chainId": chain_id,
                "gas": 500000,  # Fixed gas limit for intron calls
                "gasPrice": min(
                    int(gas_price * GAS_PRICE_MULTIPLIER),
                    MAX_GAS_PRICE
                ),
                "nonce": nonce,
            })
            
            # Sign and send transaction
            signed_tx = self.account.sign_transaction(tx)
            tx_hash = await self.web3_by_chain[chain_name].eth.send_raw_transaction(signed_tx.raw_transaction)
            
            # Wait for receipt
            receipt = await self.web3_by_chain[chain_name].eth.wait_for_transaction_receipt(tx_hash)
            logger.info(f"Factory intron() call successful, tx hash: {receipt['transactionHash'].hex()}")
            
            return receipt
            
        except Exception as e:
            logger.error(f"Error calling factory intron(): {e}")
            raise

    def decode_order_created_event(self, chain_name: str, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Decode OrderCreated event data into a more usable format.
        Returns a dictionary with parsed event data.
        """
        contract = self.get_contract(chain_name)
        event = contract.events.OrderCreated()
        decoded = event.process_log(event_data)
        
        return {
            "order_id": decoded.args.orderId,
            "refund_beneficiary": decoded.args.order[0],
            "token": decoded.args.order[1],
            "input_amount": decoded.args.order[2],
            "to": decoded.args.order[3],  # bytes20 Tron address
            "output_amount": decoded.args.order[4],
            "deadline": decoded.args.order[5],
            "block_number": event_data["blockNumber"],
            "transaction_hash": event_data["transactionHash"].hex()
        }

    async def claim_order(self, chain_name: str, order_id: bytes) -> Optional[str]:
        """
        Call claim() on UntronTransfers contract for a specific order.
        Returns transaction hash if successful.
        """
        logger.info(f"Claiming order {order_id.hex()} on chain {chain_name}")
        
        web3 = self.get_web3(chain_name)
        contract = self.get_contract(chain_name)
        
        try:
            # Build transaction
            tx = await contract.functions.claim(order_id).build_transaction({
                "from": self.account.address,
                "nonce": await web3.eth.get_transaction_count(self.account.address),
                "gas": 3000000,
                "gasPrice": min(
                    int(await web3.eth.gas_price * GAS_PRICE_MULTIPLIER),
                    MAX_GAS_PRICE
                ),
            })
            
            # Sign and send transaction
            signed_tx = self.account.sign_transaction(tx)
            tx_hash = await web3.eth.send_raw_transaction(signed_tx.raw_transaction)
            
            # Wait for receipt
            receipt = await web3.eth.wait_for_transaction_receipt(tx_hash)
            tx_hash_hex = receipt["transactionHash"].hex()
            
            logger.info(f"Successfully claimed order. Tx hash: {tx_hash_hex}")
            return tx_hash_hex
            
        except Exception as e:
            logger.error(f"Error claiming order: {e}")
            return None

# Create singleton instance
ethereum = EthereumClient()

================
File: blockchain/tron.py
================
import asyncio
import logging
from typing import Optional
from tronpy import AsyncTron
from tronpy.keys import PrivateKey
from hashlib import sha256

from ..config import CONFIG, TRON_API_URL, TRON_API_KEY

logger = logging.getLogger(__name__)

class TronClient:
    def __init__(self):
        """Initialize Tron client."""
        self.client = AsyncTron(
            provider=TRON_API_URL,
            api_key=TRON_API_KEY
        )
        self.private_key = PrivateKey(bytes.fromhex(CONFIG["tron_private_key"]))
        self.usdt_contract = self.client.get_contract("TR7NHqjeKQxGTCi8q8ZY4pL8otSzgjLj6t")  # USDT contract
        
    async def send_usdt(self, to_address: str, amount: int) -> Optional[str]:
        """
        Send USDT to a Tron address.
        Returns transaction hash if successful, None otherwise.
        """
        logger.info(f"Sending {amount} USDT to {to_address}")
        
        try:
            # Build and sign transaction
            txn = await self.usdt_contract.functions.transfer(to_address, amount).with_owner(self.private_key.public_key).build()
            signed_txn = await self.client.sign(txn, self.private_key)
            
            # Broadcast transaction
            txn_broadcast = await self.client.broadcast(signed_txn)
            
            # Run the blocking wait() in a thread executor
            loop = asyncio.get_running_loop()
            receipt = await loop.run_in_executor(None, txn_broadcast.wait)
            
            if receipt.get("result", "") == "SUCCESS":
                tx_id = receipt["id"]
                logger.info(f"Successfully sent USDT. Transaction ID: {tx_id}")
                return tx_id
            else:
                logger.error(f"Failed to send USDT: {receipt}")
                return None
                
        except Exception as e:
            logger.error(f"Error sending USDT: {e}")
            return None
    
    @staticmethod
    def eth_address_to_tron(eth_address: bytes) -> str:
        """Convert Ethereum address bytes to Tron address format."""
        import base58
        
        # Add Tron prefix (0x41)
        tron_bytes = b"\x41" + eth_address
        
        # Add checksum
        h = tron_bytes
        for _ in range(2):
            h = bytes(sha256(h).digest())
        checksum = h[:4]
        
        # Encode with Base58
        return base58.b58encode(tron_bytes + checksum).decode()

# Create singleton instance
tron = TronClient()

================
File: database/__init__.py
================
import logging
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.ext.asyncio import async_sessionmaker

from ..config import DATABASE_URL
from .models import Base

logger = logging.getLogger(__name__)

# Create async engine
engine = create_async_engine(
    DATABASE_URL.replace('sqlite:///', 'sqlite+aiosqlite:///'),
    echo=False
)

# Create async session factory
async_session = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False
)

async def setup_database():
    """Initialize the database and create tables if they don't exist."""
    try:
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logger.info("Database tables created successfully")
    except Exception as e:
        logger.error(f"Error setting up database: {e}")
        raise

async def get_session():
    """Get a database session."""
    async with async_session() as session:
        try:
            yield session
        finally:
            await session.close()

================
File: database/models.py
================
from sqlalchemy import Column, String, Integer, DateTime, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func

Base = declarative_base()

class Receiver(Base):
    """Model for tracking deployed receiver contracts."""
    __tablename__ = 'receivers'

    id = Column(Integer, primary_key=True)
    tron_address = Column(String, unique=True, nullable=False)
    eth_address = Column(String, unique=True, nullable=False)
    resolved_at = Column(DateTime, server_default=func.now())

class CaseFix(Base):
    """Model for tracking case-sensitive address mappings."""
    __tablename__ = 'case_fixes'

    id = Column(Integer, primary_key=True)
    lowercase = Column(String, unique=True, nullable=False)  # Lowercased version of the address
    original = Column(String, nullable=False)  # Original case-sensitive address
    created_at = Column(DateTime, server_default=func.now())

class ProcessedIntent(Base):
    """Model for tracking processed transfer intents to prevent duplicates."""
    __tablename__ = 'processed_intents'

    id = Column(Integer, primary_key=True)
    # Can be either order_id for UntronTransfers or receiver_address for direct transfers
    intent_id = Column(String, unique=True, nullable=False)
    eth_tx_hash = Column(String)  # Hash of the Ethereum transaction that triggered this intent
    tron_tx_hash = Column(String)  # Hash of the Tron transaction that fulfilled this intent
    amount = Column(String, nullable=False)  # Amount as string to avoid precision loss
    token = Column(String, nullable=False)  # Token symbol (e.g., "USDT", "USDC")
    source = Column(String, nullable=False)  # Either "receiver" or "order"
    is_claimed = Column(Boolean, default=False)  # Whether claim() was called on Ethereum
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, onupdate=func.now())

================
File: polling/order_listener.py
================
import asyncio
import logging
from sqlalchemy.ext.asyncio import AsyncSession

from ..blockchain.ethereum import ethereum
from ..blockchain.tron import tron
from ..config import CONFIG, ETHEREUM_POLL_INTERVAL
from ..database import get_session, ProcessedIntent
from ..utils import is_profitable, load_last_block, save_last_block

logger = logging.getLogger(__name__)

async def process_order_created_event(
    chain_name: str,
    event_data: dict,
    session: AsyncSession
) -> bool:
    """
    Process an OrderCreated event from the UntronTransfers contract.
    Returns True if the order was successfully processed.
    """
    # Decode event data
    order = ethereum.decode_order_created_event(chain_name, event_data)
    order_id_hex = order["order_id"].hex()
    
    logger.info(f"Processing OrderCreated event. orderId = {order_id_hex}")
    
    # Check if this order was already processed
    existing = await session.get(ProcessedIntent, order_id_hex)
    if existing is not None:
        if existing.source == "receiver":
            logger.info(f"Order {order_id_hex} was already filled via receiver")
            return True
        elif existing.source == "order":
            logger.info(f"Order {order_id_hex} was already processed")
            return True
    
    # Check if order is profitable
    chain_config = next(c for c in CONFIG["chains"] if c["name"] == chain_name)
    if not is_profitable(chain_config, order["token"], order["input_amount"], order["output_amount"]):
        logger.info(f"Order {order_id_hex} is not profitable")
        return False
    
    # Convert to Tron address and send USDT
    to_address = tron.eth_address_to_tron(order["to"])
    amount = order["output_amount"]
    
    tron_tx_hash = await tron.send_usdt(to_address, amount)
    if not tron_tx_hash:
        logger.error(f"Failed to send USDT for order {order_id_hex}")
        return False
    
    # Record the intent
    intent = ProcessedIntent(
        intent_id=order_id_hex,
        eth_tx_hash=order["transaction_hash"],
        tron_tx_hash=tron_tx_hash,
        amount=str(amount),
        token=order["token"],
        source="order",
        is_claimed=False
    )
    session.add(intent)
    await session.commit()
    
    # Claim the order on Ethereum
    eth_tx_hash = await ethereum.claim_order(chain_name, order["order_id"])
    if eth_tx_hash:
        intent.is_claimed = True
        await session.commit()
        logger.info(f"Successfully processed order {order_id_hex}")
        return True
    else:
        logger.error(f"Failed to claim order {order_id_hex}")
        return False

async def poll_orders(chain_name: str) -> None:
    """
    Poll for OrderCreated events from the UntronTransfers contract.
    """
    web3 = ethereum.get_web3(chain_name)
    contract = ethereum.get_contract(chain_name)
    
    last_block = await load_last_block(f"{chain_name}_orders")
    if not last_block:
        last_block = await web3.eth.block_number
        
    logger.info(f"Starting order polling for chain {chain_name} from block {last_block}")
    
    while True:
        try:
            current_block = await web3.eth.block_number
            
            if current_block > last_block:
                # Process blocks in chunks to avoid timeout
                chunk_size = 1000
                from_block = last_block + 1
                
                while from_block <= current_block:
                    to_block = min(from_block + chunk_size - 1, current_block)
                    
                    try:
                        # Get OrderCreated events
                        logs = await web3.eth.get_logs({
                            "fromBlock": from_block,
                            "toBlock": to_block,
                            "address": contract.address,
                            "topics": [
                                web3.keccak(text="OrderCreated(bytes32,(address,address,uint256,bytes20,uint256,uint256))").hex()
                            ]
                        })
                        
                        async with get_session() as session:
                            for log in logs:
                                try:
                                    await process_order_created_event(
                                        chain_name,
                                        log,
                                        session
                                    )
                                except Exception as e:
                                    logger.error(f"Error processing log: {e}")
                                    continue
                    
                    except Exception as e:
                        logger.error(
                            f"Error fetching logs for blocks {from_block}-{to_block}: {e}"
                        )
                    
                    from_block = to_block + 1
                
                last_block = current_block
                await save_last_block(f"{chain_name}_orders", last_block)
        
        except Exception as e:
            logger.error(f"Error in order polling loop: {e}")
        
        await asyncio.sleep(ETHEREUM_POLL_INTERVAL)

async def start_order_listeners() -> None:
    """Start order listeners for all configured chains."""
    tasks = []
    for chain in CONFIG["chains"]:
        logger.info(f"Starting order listener for chain: {chain['name']}")
        tasks.append(asyncio.create_task(poll_orders(chain["name"])))
    
    await asyncio.gather(*tasks)

================
File: polling/receiver_listener.py
================
import asyncio
import logging
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from ..blockchain.ethereum import ethereum
from ..blockchain.tron import tron
from ..config import CONFIG, ETHEREUM_POLL_INTERVAL
from ..database import get_session, Receiver, ProcessedIntent
from ..utils import decode_tron_address, address_to_topic, save_last_block, load_last_block, is_profitable

logger = logging.getLogger(__name__)

async def process_transfer_event(
    chain_name: str,
    event_data: dict,
    session: AsyncSession
) -> bool:
    """
    Process a token transfer event to a receiver contract.
    Returns True if the transfer was successfully processed.
    """
    # Extract transfer details
    to_address = event_data["topics"][2].hex()  # Third topic is 'to' address
    amount = int(event_data["data"], 16)  # Data field contains amount
    token_address = event_data["address"]
    
    # Check if this is a transfer to one of our receiver contracts
    receiver = await session.execute(
        select(Receiver).where(Receiver.eth_address.ilike(to_address))
    )
    receiver = receiver.scalar_one_or_none()
    
    if not receiver:
        return False  # Not a transfer to our receiver
    
    logger.info(
        f"Processing transfer to receiver {to_address} "
        f"of {amount} from token {token_address}"
    )
    
    # Generate a unique intent ID from the transaction hash
    intent_id = event_data["transactionHash"].hex()
    
    # Check if this transfer was already processed
    existing = await session.get(ProcessedIntent, intent_id)
    if existing is not None:
        logger.info(f"Transfer {intent_id} was already processed")
        return True
    
    # Check if transfer is profitable
    chain_config = next(c for c in CONFIG["chains"] if c["name"] == chain_name)
    if not is_profitable(chain_config, token_address, amount, amount):  # Same amount for input/output
        logger.info(f"Transfer {intent_id} is not profitable")
        return False
    
    # Send USDT on Tron side
    tron_tx_hash = await tron.send_usdt(receiver.tron_address, amount)
    if not tron_tx_hash:
        logger.error(f"Failed to send USDT for transfer {intent_id}")
        return False
    
    # Record the intent
    intent = ProcessedIntent(
        intent_id=intent_id,
        eth_tx_hash=event_data["transactionHash"].hex(),
        tron_tx_hash=tron_tx_hash,
        amount=str(amount),
        token=token_address,
        source="receiver",
        is_claimed=True  # No claim needed for receiver transfers
    )
    session.add(intent)
    await session.commit()

    # Call intron() through factory to handle the receiver contract
    try:
        tron_bytes = decode_tron_address(receiver.tron_address)
        if tron_bytes:
            receipt = await ethereum.call_intron(chain_name, tron_bytes)
            logger.info(f"Successfully called factory intron() for receiver {to_address}, tx: {receipt['transactionHash'].hex()}")
    except Exception as e:
        logger.error(f"Failed to call factory intron() for receiver {to_address}: {e}")
        # Don't return False here as the Tron transfer was successful
    
    logger.info(f"Successfully processed transfer {intent_id}")
    return True

async def poll_receivers(chain_name: str) -> None:
    """
    Poll for token transfers to receiver contracts on a specific chain.
    """
    web3 = ethereum.get_web3(chain_name)
    
    # Get list of token addresses to monitor
    chain_config = next(c for c in CONFIG["chains"] if c["name"] == chain_name)
    token_addresses = [
        token_data["address"]
        for token_data in chain_config["tokens"].values()
    ]
    
    # Get list of receiver addresses to monitor
    async with get_session() as session:
        receivers = await session.execute(select(Receiver))
        receiver_addresses = [r.eth_address for r in receivers.scalars().all()]
    
    if not receiver_addresses:
        logger.warning(f"No receiver contracts found for chain {chain_name}")
        return
    
    last_block = await load_last_block(f"{chain_name}_receivers")
    if not last_block:
        last_block = await web3.eth.block_number
        
    logger.info(f"Starting receiver polling for chain {chain_name} from block {last_block}")
    
    while True:
        try:
            current_block = await web3.eth.block_number
            
            if current_block > last_block:
                # Process blocks in chunks to avoid timeout
                chunk_size = 1000
                from_block = last_block + 1
                
                while from_block <= current_block:
                    to_block = min(from_block + chunk_size - 1, current_block)
                    
                    try:
                        # Get Transfer events to our receiver contracts
                        logs = await web3.eth.get_logs({
                            "fromBlock": from_block,
                            "toBlock": to_block,
                            "address": token_addresses,
                            "topics": [
                                web3.keccak(text="Transfer(address,address,uint256)").hex(),
                                None,  # Any from address
                                [address_to_topic(addr) for addr in receiver_addresses]  # To our receivers
                            ]
                        })
                        
                        async with get_session() as session:
                            for log in logs:
                                try:
                                    await process_transfer_event(
                                        chain_name,
                                        log,
                                        session
                                    )
                                except Exception as e:
                                    logger.error(f"Error processing log: {e}")
                                    continue
                    
                    except Exception as e:
                        logger.error(
                            f"Error fetching logs for blocks {from_block}-{to_block}: {e}"
                        )
                    
                    from_block = to_block + 1
                
                last_block = current_block
                await save_last_block(f"{chain_name}_receivers", last_block)
        
        except Exception as e:
            logger.error(f"Error in receiver polling loop: {e}")
        
        await asyncio.sleep(ETHEREUM_POLL_INTERVAL)

async def start_receiver_listeners() -> None:
    """Start receiver listeners for all configured chains."""
    tasks = []
    for chain in CONFIG["chains"]:
        logger.info(f"Starting receiver listener for chain: {chain['name']}")
        tasks.append(asyncio.create_task(poll_receivers(chain["name"])))
    
    await asyncio.gather(*tasks)

================
File: config.py
================
import json
import logging.config
import os
from typing import Dict, Any
from pathlib import Path

# Get the project root directory
PROJECT_ROOT = Path(__file__).parent.parent.absolute()

# Default paths
CONFIG_FILE = os.getenv("CONFIG_FILE", str(PROJECT_ROOT / "config.json"))
BACKUP_DIR = PROJECT_ROOT / "backups"
LOG_DIR = PROJECT_ROOT / "logs"

# Ensure directories exist
BACKUP_DIR.mkdir(exist_ok=True)
LOG_DIR.mkdir(exist_ok=True)

def load_config() -> Dict[str, Any]:
    """Load and validate configuration from JSON file."""
    try:
        with open(CONFIG_FILE) as f:
            config = json.load(f)
            
        # Validate all required configuration fields
        required_fields = [
            "ethereum_private_key",
            "tron_private_key",
            "trongrid_api_key",
            "receiver_factory_address",
            "receiver_implementation_address",
            "flex_swapper_address",
            "chains"
        ]
        
        missing_keys = [key for key in required_fields if key not in config]
        if missing_keys:
            raise ValueError(f"Missing required config keys: {missing_keys}")
        
        # Validate chain configurations
        for chain in config["chains"]:
            required_chain_fields = ["name", "rpc", "contract_address", "tokens"]
            missing_chain_keys = [field for field in required_chain_fields if field not in chain]
            if missing_chain_keys:
                raise ValueError(f"Missing required chain fields: {missing_chain_keys} in chain {chain.get('name', 'unknown')}")
            
            # Validate token configurations
            for token, token_config in chain["tokens"].items():
                required_token_fields = ["address", "static_fee", "percentage_fee_bps"]
                missing_token_keys = [field for field in required_token_fields if field not in token_config]
                if missing_token_keys:
                    raise ValueError(f"Missing required token fields: {missing_token_keys} for token {token} in chain {chain['name']}")
        
        return config
        
    except FileNotFoundError:
        raise FileNotFoundError(f"Config file not found: {CONFIG_FILE}")
    except json.JSONDecodeError:
        raise ValueError(f"Invalid JSON in config file: {CONFIG_FILE}")

def load_abis() -> Dict[str, Any]:
    """Load contract ABIs from JSON files."""
    try:
        # Load factory and receiver ABIs
        factory_abi = json.load(open(PROJECT_ROOT / "out/ReceiverFactory.json"))["abi"]
        receiver_abi = json.load(open(PROJECT_ROOT / "out/UntronReceiver.json"))["abi"]
        
        # Minimal UntronTransfers ABI with required events and functions
        untron_abi = [
            {
                "anonymous": False,
                "inputs": [
                    {"indexed": True, "name": "orderId", "type": "bytes32"},
                    {
                        "components": [
                            {"name": "refundBeneficiary", "type": "address"},
                            {"name": "token", "type": "address"},
                            {"name": "inputAmount", "type": "uint256"},
                            {"name": "to", "type": "bytes20"},
                            {"name": "outputAmount", "type": "uint256"},
                            {"name": "deadline", "type": "uint256"}
                        ],
                        "indexed": False,
                        "name": "order",
                        "type": "tuple"
                    }
                ],
                "name": "OrderCreated",
                "type": "event"
            },
            {
                "inputs": [{"name": "orderId", "type": "bytes32"}],
                "name": "claim",
                "outputs": [],
                "stateMutability": "nonpayable",
                "type": "function"
            }
        ]
        
        # Minimal ERC20 Transfer event ABI
        erc20_abi = [
            {
                "anonymous": False,
                "inputs": [
                    {"indexed": True, "name": "from", "type": "address"},
                    {"indexed": True, "name": "to", "type": "address"},
                    {"indexed": False, "name": "value", "type": "uint256"}
                ],
                "name": "Transfer",
                "type": "event"
            }
        ]
        
        return {
            "factory": factory_abi,
            "receiver": receiver_abi,
            "untron": untron_abi,
            "erc20": erc20_abi
        }
    except FileNotFoundError as e:
        raise FileNotFoundError(f"Missing ABI file: {e.filename}")

def setup_logging() -> None:
    """Configure application logging."""
    os.makedirs(LOG_DIR, exist_ok=True)
    
    logging_config = {
        "version": 1,
        "formatters": {
            "default": {
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            },
        },
        "handlers": {
            "file": {
                "class": "logging.handlers.RotatingFileHandler",
                "filename": str(LOG_DIR / "relayer.log"),
                "maxBytes": 10*1024*1024,  # 10MB
                "backupCount": 5,
                "formatter": "default",
            },
            "console": {
                "class": "logging.StreamHandler",
                "formatter": "default"
            }
        },
        "root": {
            "handlers": ["file", "console"],
            "level": "INFO",
        },
    }
    
    logging.config.dictConfig(logging_config)

# Initialize configuration
CONFIG = load_config()
ABIS = load_abis()
setup_logging()

# Create logger for this module
logger = logging.getLogger(__name__)

# Constants for blockchain operations
ETHEREUM_POLL_INTERVAL = 2
TRON_POLL_INTERVAL = 2
MAX_RETRIES = 3
RETRY_DELAY = 1
GAS_PRICE_MULTIPLIER = 11 / 10  # 110% of base gas price
MAX_GAS_PRICE = 100_000_000_000  # 100 gwei

# Database settings
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///receivers.db")
DB_FILENAME = str(PROJECT_ROOT / "receivers.db")

# Tron API settings
TRON_API_URL = "https://api.trongrid.io"
TRON_API_KEY = CONFIG["trongrid_api_key"]

# Cache settings
CACHE_EXPIRY = 3600  # 1 hour in seconds
MAX_CACHE_SIZE = 10000  # Maximum number of items in cache

================
File: endpoints.py
================
import logging
from aiohttp import web
from sqlalchemy import select
from base58 import b58decode_check

from .database import get_session, Receiver, CaseFix
from .blockchain.ethereum import ethereum
from .utils import run_case_fix_binary
from .config import CONFIG, normalize_address

logger = logging.getLogger(__name__)

routes = web.RouteTableDef()

@routes.post("/resolve")
async def resolve_handler(request: web.Request) -> web.Response:
    """
    Handle CCIP-Read resolution requests.
    Expects POST request with JSON body containing hex-encoded domain data.
    """
    logger.info("=== Starting new resolve request ===")
    try:
        data = await request.json()
        logger.info(f"Received request data: {data}")
        
        domain = data.get("data")
        if not domain:
            logger.error("Missing data field in request")
            return web.json_response(
                {"message": "Missing data field"},
                status=400
            )
            
        try:
            domain = bytes.fromhex(domain.lstrip("0x"))
            logger.info(f"Successfully decoded domain bytes: {domain.hex()}")
        except Exception as e:
            logger.error(f"Failed to decode domain hex: {domain}, error: {e}")
            return web.json_response(
                {"message": f"Invalid domain format: {e}"},
                status=400
            )
            
        # Extract Tron address from domain data (DNS wire format)
        subdomain_length = domain[0]
        lowercased_tron_address = domain[1:subdomain_length+1].decode().lower()
        logger.info(f"Extracted Tron address from domain: {lowercased_tron_address}")
        
        # Check cache for case fix
        async with get_session() as session:
            case_fix = await session.execute(
                select(CaseFix).where(CaseFix.lowercase == lowercased_tron_address)
            )
            case_fix = case_fix.scalar_one_or_none()
            
            if case_fix:
                fixed_tron_address = case_fix.original
                logger.info(f"Found cached case fix: {lowercased_tron_address} -> {fixed_tron_address}")
            else:
                logger.info(f"No cached case fix found for {lowercased_tron_address}, running binary...")
                # Run case fix binary if not in cache
                fixed_tron_address = await run_case_fix_binary(lowercased_tron_address)
                if fixed_tron_address:
                    logger.info(f"Successfully fixed case: {lowercased_tron_address} -> {fixed_tron_address}")
                    await session.add(CaseFix(
                        lowercase=lowercased_tron_address,
                        original=fixed_tron_address
                    ))
                    await session.commit()
                else:
                    logger.error(f"Failed to fix case for address: {lowercased_tron_address}")
                    return web.json_response(
                        {"message": "Failed to process Tron address"},
                        status=500
                    )
                
            # Decode Tron address
            try:
                raw_bytes = b58decode_check(fixed_tron_address)[1:]
            except Exception as e:
                logger.error(f"Failed to decode fixed Tron address: {fixed_tron_address} error: {e}")
                return web.json_response(
                    {"message": "Invalid Tron address"},
                    status=400
                )
            
            # Generate receiver address using default chain
            chain_name = CONFIG["default_chain"]
            receiver_address = await ethereum.generate_receiver_address(chain_name, raw_bytes)
            receiver_address = normalize_address(receiver_address)
            
            # Check if we have a receiver for this address
            receiver = await session.execute(
                select(Receiver).where(Receiver.eth_address == receiver_address)
            )
            receiver = receiver.scalar_one_or_none()
            
            if not receiver:
                # Store new receiver mapping
                await session.add(Receiver(
                    eth_address=receiver_address,
                    tron_address=fixed_tron_address
                ))
                await session.commit()
                logger.info(f"Generated and stored new receiver: {receiver_address} -> {fixed_tron_address}")
            else:
                logger.info(f"Found existing receiver: {receiver_address}")
            
            # Construct response in DNS wire format
            result = "0x" + (bytes([subdomain_length]) + fixed_tron_address.encode() + domain[subdomain_length+1:]).hex()
            logger.info(f"=== Resolve complete: {lowercased_tron_address} -> {result} ===")
            
            return web.json_response({"data": result})
            
    except Exception as e:
        logger.exception(f"Unexpected error in resolve_handler: {e}")
        return web.json_response(
            {"message": f"Internal server error: {str(e)}"},
            status=500
        )

@routes.get("/health")
async def health_check(request):
    """Simple health check endpoint."""
    return web.json_response({"status": "ok"})

def setup_routes(app: web.Application) -> None:
    """Configure routes for the web application."""
    app.add_routes(routes)

================
File: main.py
================
import asyncio
import logging
import os
from aiohttp import web
from pathlib import Path

from .config import setup_logging, PROJECT_ROOT
from .database import setup_database
from .blockchain import client
from .endpoints import setup_routes
from .polling.order_listener import start_order_listeners
from .polling.receiver_listener import start_receiver_listeners

logger = logging.getLogger(__name__)

# Get the relayer directory path
RELAYER_DIR = Path(__file__).parent.absolute()

async def init_app() -> web.Application:
    """Initialize the web application."""
    logger.info("Initializing web application")
    app = web.Application()
    setup_routes(app)
    logger.info("Web application routes configured")
    return app

async def main() -> None:
    """Main application entry point."""
    logger.info("Starting application")
    
    # Change to base58bruteforce directory and build binary
    logger.info("Building base58bruteforce binary")
    original_dir = os.getcwd()
    os.chdir(RELAYER_DIR / "base58bruteforce")
    os.system("cargo build --release")
    os.chdir(original_dir)
    os.system(f"cp {RELAYER_DIR}/base58bruteforce/target/release/base58bruteforce {RELAYER_DIR}/binary")
    
    # Initialize database
    await setup_database()
    
    # Set up blockchain contracts
    await client.setup_contracts()
    
    # Initialize and start web application
    app = await init_app()
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', 8454)
    await site.start()
    logger.info("Server started at http://0.0.0.0:8454")
    
    # Start blockchain event listeners
    logger.info("Starting blockchain event listeners")
    try:
        # Start both order and receiver listeners
        await asyncio.gather(
            start_order_listeners(),
            start_receiver_listeners()
        )
    except asyncio.CancelledError:
        logger.info("Shutting down event listeners")
    except Exception as e:
        logger.error(f"Error in main loop: {e}")
        raise
    finally:
        await runner.cleanup()

if __name__ == '__main__':
    try:
        logger.info("Starting application main loop")
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Server stopped by user")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        raise

================
File: utils.py
================
import asyncio
import logging
import os
from typing import Optional, Dict, Any
import base58
from pathlib import Path

from .config import PROJECT_ROOT

logger = logging.getLogger(__name__)

# Get the relayer directory path
RELAYER_DIR = Path(__file__).parent.absolute()

def is_profitable(chain: Dict[str, Any], token_address: str, input_amount: int, output_amount: int) -> bool:
    """
    Check if a transfer/order is profitable based on configured fees.
    Uses basis points (1/10000) for percentage calculations to avoid floats.
    Returns False if token is not in allowed list for the chain.
    
    Args:
        chain: Chain configuration dictionary
        token_address: Token contract address
        input_amount: Amount being sent on source chain
        output_amount: Amount to be sent on destination chain
    """
    # Find token config by address
    token_config = None
    token_symbol = None
    for symbol, token_data in chain["tokens"].items():
        if token_data["address"].lower() == token_address.lower():
            token_config = token_data
            token_symbol = symbol
            break
    
    if not token_config:
        logger.info(f"Token {token_address} not in allowed tokens list for chain {chain['name']}")
        return False
    
    # Calculate total fee (static + percentage)
    percentage_fee = (output_amount * token_config["percentage_fee_bps"]) // 10000
    total_fee = token_config["static_fee"] + percentage_fee
    
    # Transfer is profitable if input covers output plus fees
    is_profitable = input_amount >= (output_amount + total_fee)

    logger.info(
        f"Profitability check for {token_symbol} - "
        f"Input: {input_amount}, "
        f"Output: {output_amount}, "
        f"Fee: {total_fee}, "
        f"Result: {is_profitable}"
    )
    
    if not is_profitable:
        logger.info(
            f"[{chain['name']}] {token_symbol} transfer not profitable - "
            f"Input: {input_amount}, "
            f"Output: {output_amount}, "
            f"Fee: {total_fee}"
        )
    
    return is_profitable

async def run_case_fix_binary(address: str) -> str:
    """Run the base58bruteforce binary asynchronously."""
    try:
        process = await asyncio.create_subprocess_exec(
            str(RELAYER_DIR / "binary"), address,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await process.communicate()
        if stdout:
            return stdout.decode().strip()
        if stderr:
            logger.error(f"Error from case fix binary: {stderr.decode()}")
        return ""
    except Exception as e:
        logger.exception(f"Error running case fix binary: {e}")
        return ""

def address_to_topic(address: str) -> str:
    """Convert an Ethereum address to a 32-byte topic."""
    if address.startswith("0x"):
        address = address[2:]
    return "0x" + address.rjust(64, "0")

async def save_last_block(chain_name: str, block_number: int) -> None:
    """Save the last processed block number for a chain."""
    os.makedirs(PROJECT_ROOT / "backups", exist_ok=True)
    with open(PROJECT_ROOT / "backups" / f"last_block_{chain_name}.txt", "w") as f:
        f.write(str(block_number))

async def load_last_block(chain_name: str) -> int:
    """Load the last processed block number for a chain."""
    try:
        with open(PROJECT_ROOT / "backups" / f"last_block_{chain_name}.txt", "r") as f:
            return int(f.read().strip())
    except FileNotFoundError:
        return 0

def decode_tron_address(tron_address: str) -> Optional[bytes]:
    """Decode a Tron address to bytes, returning None if invalid."""
    try:
        return base58.b58decode_check(tron_address)[1:]
    except Exception as e:
        logger.error(f"Error decoding Tron address {tron_address}: {e}")
        return None

def validate_tron_address(tron_address: str) -> bool:
    """Validate a Tron address format."""
    if not isinstance(tron_address, str):
        return False
    if len(tron_address) not in range(25, 35):
        return False
    try:
        decode_tron_address(tron_address)
        return True
    except Exception:
        return False



================================================================
End of Codebase
================================================================
